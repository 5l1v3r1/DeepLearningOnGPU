https://audiodemos.github.io/ 仅采用的少量的样本，就可以复制声音。


阿里的http://mp.weixin.qq.com/s/JSnyE2k7jqd5GR1lHA6WUg论文历史和未来信息各捕捉120帧（600ms)是语音合成声学模型
建模所需要的上下文长度的上限。它的模型更简单，计算量更小。
并且前馈序列记忆神经网 科大迅飞已经发了专利:https://patents.google.com/patent/CN106919977A/zh

双向RNN，在实用中只有获得完整的全部语音段，才能成功利用未来的信息，这就使其具有很大时延，只能用于处理一些离一任务。
而对于实时语音交互，例如语音输入法。就有点不适用。  并RNN对上下文相当性的拟合性较强，相对于DNN更容易陷入过拟合。
容易因为训练数据的局部不鲁棒现象而带来额外的异常识别错误。最后，由于RNN具有比DNN更加复杂的结构，给海量数据下的RNN模型训练带来了更大的挑战


